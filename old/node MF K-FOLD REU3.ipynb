{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "\n",
    "import time\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out if using Leave One Out\n",
    "K = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, jacfwd, vmap, random\n",
    "from jax.experimental.ode import odeint\n",
    "\n",
    "# import MCMC library\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, HMC\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "### Basic usage ###\n",
    "\n",
    "'''\n",
    "# import ODE\n",
    "from autode.autode import ODE\n",
    "\n",
    "# instantiate ODE fit\n",
    "model = ODE(system, df, params)\n",
    "\n",
    "# fit to data\n",
    "params = model.fit()\n",
    "\n",
    "where df has columns [Time, Treatments, S1, ..., SN]\n",
    "'''\n",
    "\n",
    "# define function that returns model sensitivity vector\n",
    "def runODE(t_eval, x, params, ctrl_params, dX_dt):\n",
    "    # solve ODE model\n",
    "    y = odeint(dX_dt, x, t_eval, params, ctrl_params)\n",
    "    return y\n",
    "\n",
    "# function to compute ODE gradients\n",
    "def dZdt(system, Z, t, x, params, ctrl_params):\n",
    "\n",
    "    # compute Jacobian (gradient of model w.r.t. x)\n",
    "    Jx = jacfwd(system, 1)(t, x, params, ctrl_params)\n",
    "\n",
    "    # compute gradient of model w.r.t. parameters\n",
    "    Jp = jacfwd(system, 2)(t, x, params, ctrl_params)\n",
    "\n",
    "    return Jx@Z + Jp\n",
    "\n",
    "# define function that returns model sensitivity vector\n",
    "def runODEZ(t_eval, x, params, ctrl_params, dXZ_dt):\n",
    "    # check dimensions\n",
    "    dim_x = len(x)\n",
    "    n_params = len(params)\n",
    "    dim_z = dim_x*n_params\n",
    "\n",
    "    # set initial condition to z equal to zeros\n",
    "    xz = jnp.concatenate((x, np.zeros(dim_z)))\n",
    "\n",
    "    # solve ODE model\n",
    "    y = odeint(dXZ_dt, xz, t_eval, params, ctrl_params)\n",
    "\n",
    "    return y\n",
    "\n",
    "### Function to process dataframes ###\n",
    "\n",
    "def process_df(df, sys_vars, measured_vars, controls):\n",
    "    # store treatment names\n",
    "    all_treatments = df.Treatments.values\n",
    "    unique_treatments = np.unique(all_treatments)\n",
    "\n",
    "    # store measured datasets for quick access\n",
    "    data = []\n",
    "    for i,treatment in enumerate(unique_treatments):\n",
    "\n",
    "        # pull community trajectory\n",
    "        comm_inds = np.in1d(df['Treatments'].values, treatment)\n",
    "        comm_data = df.iloc[comm_inds].copy()\n",
    "\n",
    "        # make sure comm_data is sorted in chronological order\n",
    "        comm_data.sort_values(by='Time', ascending=True, inplace=True)\n",
    "\n",
    "        # pull evaluation times\n",
    "        t_eval = np.array(comm_data['Time'].values, float)\n",
    "\n",
    "        # pull initial condition\n",
    "        Y_init = np.array(comm_data[sys_vars].values[0], float)\n",
    "        \n",
    "        # pull system data\n",
    "        Y_measured = np.array(comm_data[measured_vars].values, float)\n",
    "\n",
    "        # pull control params\n",
    "        ctrl_params = np.array(comm_data[controls].values, float)\n",
    "\n",
    "        # append t_eval and Y_measured to data list\n",
    "        data.append([t_eval, Y_init, Y_measured, ctrl_params])\n",
    "\n",
    "    return data\n",
    "\n",
    "class ODE:\n",
    "    def __init__(self, system, dataframes, compressors, params, sys_vars, measured_vars, controls = [],\n",
    "                 alpha_0=1., prior=None, verbose=True):\n",
    "        '''\n",
    "        system: a system of differential equations\n",
    "\n",
    "        dfs: dataframes each with columns\n",
    "        [Treatment], [Time], [x_1], ..., [x_n], [control_1], ..., [control_m]\n",
    "\n",
    "        sys_vars: List of variable names of all model outputs as they appear in\n",
    "                  dataframe (df). (Includes measured and unobserved outputs)\n",
    "\n",
    "        params: initial guess of model parameters\n",
    "\n",
    "        measured_sys_vars: List of observed (measured) model outputs\n",
    "\n",
    "        control_param\n",
    "\n",
    "        '''\n",
    "\n",
    "        # make sure params are 1-dimensional\n",
    "        self.params = np.array(params).ravel()\n",
    "        if prior is not None:\n",
    "            self.prior = np.array(prior).ravel()\n",
    "        else:\n",
    "            self.prior = np.zeros_like(params)\n",
    "\n",
    "        # initial degree of regularization\n",
    "        self.alpha_0 = alpha_0\n",
    "\n",
    "        # number of parameters\n",
    "        self.n_params = len(params)\n",
    "\n",
    "        # dimension of model output\n",
    "        self.sys_vars = sys_vars\n",
    "        self.measured_vars = measured_vars\n",
    "        self.n_sys_vars = len(sys_vars)\n",
    "\n",
    "        # control input\n",
    "        self.controls = controls\n",
    "        self.n_ctrls = len(controls)\n",
    "\n",
    "        # set compressors \n",
    "        self.compressors = []\n",
    "        for compressor in compressors:\n",
    "            # vmap over all time points \n",
    "            self.compressors.append(jit(vmap(compressor)))\n",
    "        \n",
    "        # store derivative of compressors \n",
    "        self.compressor_primes = []\n",
    "        for compressor in compressors:\n",
    "            # vmap over all time points \n",
    "            self.compressor_primes.append(jit(vmap(jacfwd(compressor))))\n",
    "            \n",
    "        # set up data\n",
    "        self.datasets = []\n",
    "        for i,(df, measured_var) in enumerate(zip(dataframes, measured_vars)):\n",
    "            self.datasets.append(process_df(df, sys_vars, measured_var, controls))\n",
    "            \n",
    "        # for additional output messages\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # set parameters of precision hyper-priors\n",
    "        self.a = 1e-4\n",
    "        self.b = 1e-4\n",
    "\n",
    "        # set posterior parameter precision and covariance to None\n",
    "        self.A = None\n",
    "        self.Ainv = None\n",
    "\n",
    "        # jit compile differential equation\n",
    "        def dX_dt(x, t, params, ctrl_params):\n",
    "            # concatentate x and z\n",
    "            return system(t, x, params, ctrl_params)\n",
    "        self.dX_dt = jit(dX_dt)\n",
    "\n",
    "        # if not vectorized, xz will be 1-D\n",
    "        dim_z = len(sys_vars)*len(params)\n",
    "        def dXZ_dt(xz, t, params, ctrl_params):\n",
    "            # split up x and z\n",
    "            x = xz[:len(sys_vars)]\n",
    "            Z = jnp.reshape(xz[len(sys_vars):], [len(sys_vars), len(params)])\n",
    "            dzdt = jnp.reshape(dZdt(system, Z, t, x, params, ctrl_params), dim_z)\n",
    "\n",
    "            # concatentate x and z\n",
    "            dXZdt = jnp.concatenate([system(t, x, params, ctrl_params), dzdt])\n",
    "            return dXZdt\n",
    "        self.dXZ_dt = jit(dXZ_dt)\n",
    "\n",
    "        # jit compile function to integrate ODE\n",
    "        self.runODE  = jit(lambda t_eval, x, params, ctrl_params: runODE(t_eval, x, params, ctrl_params, self.dX_dt))\n",
    "        self.runODEZ = jit(lambda t_eval, x, params, ctrl_params: runODEZ(t_eval, x, params, ctrl_params, self.dXZ_dt))\n",
    "\n",
    "        # jit compile matrix operations\n",
    "        def SSE_next(Y_error, G, Ainv):\n",
    "            return jnp.sum(Y_error**2) + jnp.einsum('tki,ij,tlj->', G, Ainv, G)\n",
    "        self.SSE_next = jit(SSE_next)\n",
    "\n",
    "        def yCOV_next(Y_error, G, Ainv):\n",
    "            return jnp.einsum('tk,tl->kl', Y_error, Y_error) + jnp.einsum('tki,ij,tlj->kl', G, Ainv, G)\n",
    "        self.yCOV_next = jit(yCOV_next)\n",
    "\n",
    "        def A_next(G, Beta):\n",
    "            return jnp.einsum('tki, kl, tlj->ij', G, Beta, G)\n",
    "        self.A_next = jit(A_next)\n",
    "\n",
    "        def GAinvG(G, Ainv):\n",
    "            return jnp.einsum('tki,ij,tlj->tkl', G, Ainv, G)\n",
    "        self.GAinvG = jit(GAinvG)\n",
    "\n",
    "        def NewtonStep(A, g):\n",
    "            return jnp.linalg.solve(A,g)\n",
    "        self.NewtonStep = jit(NewtonStep)\n",
    "\n",
    "        def eval_grad_NLP(Y_error, Beta, G):\n",
    "            return jnp.einsum('tk,kl,tli->i', Y_error, Beta, G)\n",
    "        self.eval_grad_NLP = jit(eval_grad_NLP)\n",
    "\n",
    "    def fit(self, evidence_tol=1e-3, beta_tol=1e-3):\n",
    "        # estimate parameters using gradient descent\n",
    "        convergence = np.inf\n",
    "        previdence  = -np.inf\n",
    "\n",
    "        while convergence > evidence_tol:\n",
    "            # update Alpha and Beta hyper-parameters\n",
    "            self.update_precision()\n",
    "            # fit using updated Alpha and Beta\n",
    "            self.res = minimize(fun=self.objective, x0=self.params,\n",
    "                       jac=True, hess=self.hessian, tol=beta_tol,\n",
    "                       method='Newton-CG',\n",
    "                       callback=self.callback)\n",
    "            if self.verbose:\n",
    "                print(self.res)\n",
    "            self.params = self.res.x\n",
    "            # update covariance\n",
    "            self.update_covariance()\n",
    "            # update evidence\n",
    "            self.update_evidence()\n",
    "            # check convergence\n",
    "            convergence = np.abs(previdence - self.evidence) / np.max([1.,np.abs(self.evidence)])\n",
    "            # update evidence\n",
    "            previdence = np.copy(self.evidence)\n",
    "\n",
    "    # EM algorithm to update hyper-parameters\n",
    "    def update_precision(self):\n",
    "        print(\"Updating precision...\")\n",
    "\n",
    "        # initialize precision parameters\n",
    "        self.N = []\n",
    "        self.beta = []\n",
    "        self.Beta = []\n",
    "\n",
    "        # loop over datasets\n",
    "        for i,dataset in enumerate(self.datasets):\n",
    "            # loop over each sample in dataset\n",
    "            SSE = 0.\n",
    "            yCOV = 0.\n",
    "            N = 0\n",
    "            for t_eval, Y_init, Y_compressed, ctrl_params in dataset:\n",
    "                \n",
    "                # count number of observations\n",
    "                N += len(t_eval[1:]) * np.sum(np.std(Y_compressed, 0) > 0) / self.n_sys_vars\n",
    "\n",
    "                # run model using current parameters\n",
    "                if self.A is None:\n",
    "                    # run ODE on initial condition \n",
    "                    output = self.runODE(t_eval, Y_init, self.params, ctrl_params)\n",
    "\n",
    "                    # Determine SSE\n",
    "                    Y_error = self.compressors[i](output) - Y_compressed\n",
    "                    SSE  += np.sum(Y_error**2)\n",
    "                    yCOV += np.einsum('tk,tl->kl', Y_error, Y_error)\n",
    "                else:\n",
    "                    # run model using current parameters, output = [n_time, n_sys_vars]\n",
    "                    output = self.runODEZ(t_eval, Y_init, self.params, ctrl_params)\n",
    "                    Y_predicted = output[:, :self.n_sys_vars]\n",
    "\n",
    "                    # collect gradients and reshape\n",
    "                    G = np.reshape(output[:, self.n_sys_vars:],\n",
    "                                  [output.shape[0], self.n_sys_vars, self.n_params])\n",
    "                    \n",
    "                    # compress model output and gradient \n",
    "                    G = np.einsum('tck,tki->tci', self.compressor_primes[i](Y_predicted), G) \n",
    "                    Y_predicted = self.compressors[i](Y_predicted)\n",
    "                    \n",
    "                    # Determine SSE\n",
    "                    Y_error = Y_predicted - Y_compressed\n",
    "                    SSE  += self.SSE_next(Y_error, G, self.Ainv)\n",
    "                    yCOV += self.yCOV_next(Y_error, G, self.Ainv)\n",
    "\n",
    "            ### M step: update hyper-parameters ###\n",
    "            self.N.append(N)\n",
    "            if self.A is None:\n",
    "                # target precision\n",
    "                self.Beta.append(N*np.linalg.inv(yCOV + 2.*self.b*np.eye(Y_compressed.shape[-1])))\n",
    "            else:\n",
    "                # maximize complete data log-likelihood w.r.t. beta\n",
    "                self.beta.append(N*Y_compressed.shape[-1]/(SSE + 2.*self.b))\n",
    "                Beta = N*np.linalg.inv(yCOV + 2.*self.b*np.eye(Y_compressed.shape[-1]))\n",
    "                Beta = (Beta + Beta.T)/2.\n",
    "                self.Beta.append(Beta)\n",
    "                # self.Beta.append(N/(SSE + 2.*self.b)*np.eye(Y_compressed.shape[-1]))\n",
    "\n",
    "        ### M step: update hyper-parameters ###\n",
    "        if self.A is None:\n",
    "            # initial guess of parameter precision\n",
    "            self.alpha = self.alpha_0\n",
    "            self.Alpha = self.alpha_0*np.ones(self.n_params)\n",
    "        else:\n",
    "            # maximize complete data log-likelihood w.r.t. alpha and beta\n",
    "            self.alpha = self.n_params/(np.dot(self.params-self.prior, self.params-self.prior) + np.trace(self.Ainv) + 2.*self.a)\n",
    "            #self.Alpha = self.alpha*np.ones(self.n_params)\n",
    "            self.Alpha = 1./((self.params-self.prior)**2 + np.diag(self.Ainv) + 2.*self.a)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Total samples: {:.0f}, Updated regularization: {:.2e}\".format(np.sum(self.N), self.alpha))\n",
    "\n",
    "    def objective(self, params):\n",
    "        # compute residuals\n",
    "        self.RES = 0.\n",
    "        # compute negative log posterior (NLP)\n",
    "        self.NLP = np.sum(self.Alpha * (params-self.prior)**2) / 2.\n",
    "        # compute gradient of negative log posterior\n",
    "        self.grad_NLP = self.Alpha*(params-self.prior)\n",
    "\n",
    "        # compute Hessian, covariance of y, sum of squares error\n",
    "        self.A = np.diag(self.Alpha)\n",
    "\n",
    "        for i, dataset in enumerate(self.datasets):\n",
    "            # loop over each sample in dataset\n",
    "            for t_eval, Y_init, Y_compressed, ctrl_params in dataset:            \n",
    "                \n",
    "                # run model using current parameters, output = [n_time, n_sys_vars]\n",
    "                output = self.runODEZ(t_eval, Y_init, params, ctrl_params)\n",
    "                Y_predicted = output[:, :self.n_sys_vars]\n",
    "\n",
    "                # collect gradients and reshape\n",
    "                G = np.reshape(output[:, self.n_sys_vars:],\n",
    "                              [output.shape[0], self.n_sys_vars, self.n_params])\n",
    "\n",
    "                # compress model output and gradient \n",
    "                G = np.einsum('tck,tki->tci', self.compressor_primes[i](Y_predicted), G) \n",
    "                Y_predicted = self.compressors[i](Y_predicted)\n",
    "                \n",
    "                # Determine error\n",
    "                Y_error = Y_predicted - Y_compressed \n",
    "\n",
    "                # compute Hessian\n",
    "                self.A += self.A_next(G, self.Beta[i])\n",
    "\n",
    "                # Determine SSE and gradient of SSE\n",
    "                self.NLP += np.einsum('tk,kl,tl->', Y_error, self.Beta[i], Y_error)/2.\n",
    "                self.RES += np.sum(Y_error)/self.N[i]\n",
    "\n",
    "                # sum over time and outputs to get gradient w.r.t params\n",
    "                self.grad_NLP += self.eval_grad_NLP(Y_error, self.Beta[i], G)\n",
    "\n",
    "        # make sure precision is symmetric\n",
    "        self.A = (self.A + self.A.T)/2.\n",
    "\n",
    "        # return NLP and gradient of NLP\n",
    "        return self.NLP, self.grad_NLP\n",
    "\n",
    "    def update_covariance(self):\n",
    "        # update parameter covariance matrix given current parameter estimate\n",
    "        if self.A is None:\n",
    "            self.A = self.alpha_0*np.eye(self.n_params)\n",
    "        else:\n",
    "            self.A = np.diag(self.Alpha)\n",
    "\n",
    "        # loop over datasets\n",
    "        for i, dataset in enumerate(self.datasets):\n",
    "            # loop over each sample in dataset\n",
    "            for t_eval, Y_init, Y_compressed, ctrl_params in dataset:\n",
    "\n",
    "                # run model using current parameters, output = [n_time, n_sys_vars]\n",
    "                output = self.runODEZ(t_eval, Y_init, self.params, ctrl_params)\n",
    "                Y_predicted = output[:, :self.n_sys_vars]\n",
    "\n",
    "                # collect gradients and reshape\n",
    "                G = np.reshape(output[:, self.n_sys_vars:],\n",
    "                              [output.shape[0], self.n_sys_vars, self.n_params])\n",
    "\n",
    "                # compress model output and gradient \n",
    "                G = np.einsum('tck,tki->tci', self.compressor_primes[i](Y_predicted), G) \n",
    "                \n",
    "                # compute Hessian\n",
    "                self.A += self.A_next(G, self.Beta[i])\n",
    "\n",
    "        # Laplace approximation of posterior covariance\n",
    "        self.A = (self.A + self.A.T)/2.\n",
    "        self.Ainv = np.linalg.inv(self.A)\n",
    "        self.Ainv = (self.Ainv + self.Ainv.T)/2.\n",
    "\n",
    "    def update_evidence(self):\n",
    "        # compute evidence\n",
    "        self.evidence = np.sum(np.log(self.Alpha))/2. - \\\n",
    "                        np.sum(np.log(np.linalg.eigvalsh(self.A)))/2. - \\\n",
    "                        self.NLP\n",
    "\n",
    "        # loop over precision matrices from each dataset\n",
    "        for N, Beta in zip(self.N, self.Beta):\n",
    "            self.evidence += N*np.sum(np.log(np.linalg.eigvalsh(Beta)))/2.\n",
    "        print(\"Evidence {:.3f}\".format(self.evidence))\n",
    "\n",
    "    def jacobian(self, params):\n",
    "        # compute gradient of cost function\n",
    "        return self.grad_NLP\n",
    "\n",
    "    def hessian(self, params):\n",
    "        # compute hessian of NLP\n",
    "        return self.A\n",
    "\n",
    "    def callback(self, xk, res=None):\n",
    "        if self.verbose:\n",
    "            print(\"Total weighted fitting error: {:.3f}\".format(self.NLP))\n",
    "        return True\n",
    "\n",
    "    def predict(self, x_test, teval, ctrl_params=[], compressor=-1):\n",
    "        # check if precision has been computed\n",
    "        if self.A is None:\n",
    "            self.update_covariance()\n",
    "\n",
    "        # make predictions given initial conditions and evaluation times\n",
    "        output = self.runODEZ(teval, x_test, self.params, ctrl_params)\n",
    "\n",
    "        # reshape gradient\n",
    "        G = np.reshape(output[:, self.n_sys_vars:],\n",
    "                       [output.shape[0], self.n_sys_vars, self.n_params])\n",
    "\n",
    "        # compress model output\n",
    "        Y_predicted = output[:, :self.n_sys_vars]\n",
    "\n",
    "        # calculate variance of each output (dimension = [steps, outputs])\n",
    "        covariance = 1./self.beta[compressor] + self.GAinvG(G, self.Ainv)\n",
    "        get_diag = vmap(jnp.diag, (0,))\n",
    "        stdv = np.sqrt(get_diag(covariance))\n",
    "\n",
    "        return Y_predicted, stdv, covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Inulin</th>\n",
       "      <th>Starch</th>\n",
       "      <th>Pectin</th>\n",
       "      <th>ArGal</th>\n",
       "      <th>Gum</th>\n",
       "      <th>AmAc</th>\n",
       "      <th>pH</th>\n",
       "      <th>BAabs</th>\n",
       "      <th>BPabs</th>\n",
       "      <th>...</th>\n",
       "      <th>PJabs</th>\n",
       "      <th>ACabs</th>\n",
       "      <th>CGabs</th>\n",
       "      <th>CHabs</th>\n",
       "      <th>FPabs</th>\n",
       "      <th>ERabs</th>\n",
       "      <th>BHabs</th>\n",
       "      <th>RIabs</th>\n",
       "      <th>CSabs</th>\n",
       "      <th>EHabs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.185000</td>\n",
       "      <td>0.195693</td>\n",
       "      <td>0.195882</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.195792</td>\n",
       "      <td>0.195836</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.030467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.254213</td>\n",
       "      <td>0.261085</td>\n",
       "      <td>0.261183</td>\n",
       "      <td>0.283816</td>\n",
       "      <td>0.261136</td>\n",
       "      <td>0.261160</td>\n",
       "      <td>0.497251</td>\n",
       "      <td>0.497251</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.051681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.185000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.370000</td>\n",
       "      <td>0.333369</td>\n",
       "      <td>0.334456</td>\n",
       "      <td>0.333762</td>\n",
       "      <td>0.333404</td>\n",
       "      <td>0.333616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.044809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.370000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110081</td>\n",
       "      <td>0.241349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023777</td>\n",
       "      <td>0.044670</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.027096</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.050191</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time     Inulin     Starch     Pectin      ArGal        Gum  \\\n",
       "count  96.000000  96.000000  96.000000  96.000000  96.000000  96.000000   \n",
       "mean   13.185000   0.195693   0.195882   0.216797   0.195792   0.195836   \n",
       "std    13.254213   0.261085   0.261183   0.283816   0.261136   0.261160   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "50%    13.185000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "75%    26.370000   0.333369   0.334456   0.333762   0.333404   0.333616   \n",
       "max    26.370000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "            AmAc         pH      BAabs      BPabs  ...      PJabs      ACabs  \\\n",
       "count  96.000000  96.000000  96.000000  96.000000  ...  96.000000  96.000000   \n",
       "mean    0.510417   0.510417   0.008104   0.030467  ...   0.002928   0.003297   \n",
       "std     0.497251   0.497251   0.018722   0.051681  ...   0.004020   0.006745   \n",
       "min     0.000000   0.000000   0.000000   0.000000  ...   0.000000   0.000000   \n",
       "25%     0.000000   0.000000   0.000667   0.000667  ...   0.000667   0.000667   \n",
       "50%     0.750000   0.750000   0.000667   0.000667  ...   0.000667   0.000667   \n",
       "75%     1.000000   1.000000   0.004173   0.044809  ...   0.003485   0.001384   \n",
       "max     1.000000   1.000000   0.110081   0.241349  ...   0.023777   0.044670   \n",
       "\n",
       "           CGabs      CHabs      FPabs      ERabs      BHabs      RIabs  \\\n",
       "count  96.000000  96.000000  96.000000  96.000000  96.000000  96.000000   \n",
       "mean    0.002506   0.003631   0.000420   0.000478   0.000548   0.000434   \n",
       "std     0.003926   0.005899   0.000267   0.000492   0.000842   0.000249   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.000667   0.000667   0.000151   0.000169   0.000116   0.000184   \n",
       "50%     0.000667   0.000667   0.000622   0.000667   0.000667   0.000606   \n",
       "75%     0.002288   0.004315   0.000667   0.000667   0.000667   0.000667   \n",
       "max     0.015978   0.027096   0.000667   0.004437   0.007572   0.000667   \n",
       "\n",
       "           CSabs      EHabs  \n",
       "count  96.000000  96.000000  \n",
       "mean    0.003535   0.000346  \n",
       "std     0.009137   0.000324  \n",
       "min     0.000000   0.000000  \n",
       "25%     0.000552   0.000020  \n",
       "50%     0.000667   0.000398  \n",
       "75%     0.000667   0.000667  \n",
       "max     0.050191   0.000667  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0_data = pd.read_csv(\"DTL0/REU03_table_t0_20220811.csv\")\n",
    "tf_data = pd.read_csv(\"DTL0/REU03_table_tf_20220811.csv\")\n",
    "\n",
    "exp_info = ['Treatments', 'Rep', 'Time']\n",
    "inputs = ['Inulin', 'Starch', 'Pectin', 'ArGal', 'Gum', 'AmAc', 'pH']\n",
    "species = ['BAabs', 'BPabs', 'BTabs', 'BUabs', 'PCabs', 'PJabs',\n",
    "       'ACabs', 'CGabs', 'CHabs', 'FPabs', 'ERabs', 'BHabs', 'RIabs',\n",
    "       'CSabs', 'EHabs']\n",
    "\n",
    "# data with replicates\n",
    "reps_data = pd.concat((t0_data[exp_info+inputs+species], tf_data[exp_info+inputs+species]))\n",
    "rep1_data = reps_data.iloc[reps_data['Rep'].values==1].sort_values(by=['Treatments', 'Time'])\n",
    "rep2_data = reps_data.iloc[reps_data['Rep'].values==2].sort_values(by=['Treatments', 'Time'])\n",
    "\n",
    "# average replicates\n",
    "avg_data = rep1_data.copy().drop(['Rep'], axis=1)\n",
    "avg_data[species] = (avg_data[species].values + rep2_data[species].values)/2.\n",
    "\n",
    "# normalize data \n",
    "t0_inds = avg_data.Time.values == 0.\n",
    "\n",
    "# normalize values after initial condition \n",
    "max_od = 1. # np.max(avg_data[species].iloc[~t0_inds].values, 0)  \n",
    "species_inds = np.in1d(avg_data.columns.values, species)\n",
    "# avg_data.iloc[~t0_inds, species_inds] /= max_od\n",
    "\n",
    "# set initial conditions \n",
    "# avg_data.iloc[t0_inds, species_inds] = np.ceil(avg_data.iloc[t0_inds, species_inds].values) / len(species)\n",
    "\n",
    "avg_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Inulin</th>\n",
       "      <th>Starch</th>\n",
       "      <th>Pectin</th>\n",
       "      <th>ArGal</th>\n",
       "      <th>Gum</th>\n",
       "      <th>AmAc</th>\n",
       "      <th>pH</th>\n",
       "      <th>OD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "      <td>672.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.350218</td>\n",
       "      <td>0.195693</td>\n",
       "      <td>0.195882</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.195792</td>\n",
       "      <td>0.195836</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.138112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.113401</td>\n",
       "      <td>0.259915</td>\n",
       "      <td>0.260012</td>\n",
       "      <td>0.282544</td>\n",
       "      <td>0.259966</td>\n",
       "      <td>0.259990</td>\n",
       "      <td>0.495023</td>\n",
       "      <td>0.495023</td>\n",
       "      <td>0.124472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.375556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.376944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.098247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.378611</td>\n",
       "      <td>0.333369</td>\n",
       "      <td>0.334456</td>\n",
       "      <td>0.333762</td>\n",
       "      <td>0.333404</td>\n",
       "      <td>0.333616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.379167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.547167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time      Inulin      Starch      Pectin       ArGal         Gum  \\\n",
       "count  672.000000  672.000000  672.000000  672.000000  672.000000  672.000000   \n",
       "mean    13.350218    0.195693    0.195882    0.216797    0.195792    0.195836   \n",
       "std      8.113401    0.259915    0.260012    0.282544    0.259966    0.259990   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      6.375556    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     13.376944    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%     20.378611    0.333369    0.334456    0.333762    0.333404    0.333616   \n",
       "max     26.379167    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             AmAc          pH          OD  \n",
       "count  672.000000  672.000000  672.000000  \n",
       "mean     0.510417    0.510417    0.138112  \n",
       "std      0.495023    0.495023    0.124472  \n",
       "min      0.000000    0.000000   -0.001833  \n",
       "25%      0.000000    0.000000    0.038898  \n",
       "50%      0.750000    0.750000    0.098247  \n",
       "75%      1.000000    1.000000    0.204613  \n",
       "max      1.000000    1.000000    0.547167  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import mono-culture data\n",
    "mono_data = pd.read_csv(\"DTL0/REU03_table_timeSeriesData_20220811.csv\")\n",
    "\n",
    "# data with replicates\n",
    "reps_data = mono_data[exp_info+inputs+['OD']].copy()\n",
    "rep1_data = reps_data.iloc[reps_data['Rep'].values==1].sort_values(by=['Treatments', 'Time'])\n",
    "rep2_data = reps_data.iloc[reps_data['Rep'].values==2].sort_values(by=['Treatments', 'Time'])\n",
    "\n",
    "# average replicates\n",
    "avg_mono_data = rep1_data.copy().drop(['Rep'], axis=1)\n",
    "avg_mono_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatments</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inulin</th>\n",
       "      <th>Starch</th>\n",
       "      <th>Pectin</th>\n",
       "      <th>ArGal</th>\n",
       "      <th>Gum</th>\n",
       "      <th>AmAc</th>\n",
       "      <th>pH</th>\n",
       "      <th>OD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>4.375278</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>6.375556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>8.375833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>REU03_9</td>\n",
       "      <td>18.378056</td>\n",
       "      <td>0.334311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>REU03_9</td>\n",
       "      <td>20.378611</td>\n",
       "      <td>0.334311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>REU03_9</td>\n",
       "      <td>22.378611</td>\n",
       "      <td>0.334311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>REU03_9</td>\n",
       "      <td>24.378889</td>\n",
       "      <td>0.334311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>REU03_9</td>\n",
       "      <td>26.379167</td>\n",
       "      <td>0.334311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.332844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Treatments       Time    Inulin  Starch    Pectin     ArGal  Gum  AmAc  \\\n",
       "0      REU03_1   0.000000  0.500000     0.0  0.000000  0.000000  0.5   0.0   \n",
       "1      REU03_1   2.375000  0.500000     0.0  0.000000  0.000000  0.5   0.0   \n",
       "2      REU03_1   4.375278  0.500000     0.0  0.000000  0.000000  0.5   0.0   \n",
       "3      REU03_1   6.375556  0.500000     0.0  0.000000  0.000000  0.5   0.0   \n",
       "4      REU03_1   8.375833  0.500000     0.0  0.000000  0.000000  0.5   0.0   \n",
       "..         ...        ...       ...     ...       ...       ...  ...   ...   \n",
       "121    REU03_9  18.378056  0.334311     0.0  0.332844  0.332844  0.0   0.0   \n",
       "122    REU03_9  20.378611  0.334311     0.0  0.332844  0.332844  0.0   0.0   \n",
       "123    REU03_9  22.378611  0.334311     0.0  0.332844  0.332844  0.0   0.0   \n",
       "124    REU03_9  24.378889  0.334311     0.0  0.332844  0.332844  0.0   0.0   \n",
       "125    REU03_9  26.379167  0.334311     0.0  0.332844  0.332844  0.0   0.0   \n",
       "\n",
       "      pH        OD  \n",
       "0    1.0  0.010000  \n",
       "1    1.0  0.042733  \n",
       "2    1.0  0.047980  \n",
       "3    1.0  0.055872  \n",
       "4    1.0  0.070998  \n",
       "..   ...       ...  \n",
       "121  0.0  0.016883  \n",
       "122  0.0  0.017573  \n",
       "123  0.0  0.018705  \n",
       "124  0.0  0.019624  \n",
       "125  0.0  0.020967  \n",
       "\n",
       "[672 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_mono_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatments</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inulin</th>\n",
       "      <th>Starch</th>\n",
       "      <th>Pectin</th>\n",
       "      <th>ArGal</th>\n",
       "      <th>Gum</th>\n",
       "      <th>AmAc</th>\n",
       "      <th>pH</th>\n",
       "      <th>OD</th>\n",
       "      <th>...</th>\n",
       "      <th>PJabs</th>\n",
       "      <th>ACabs</th>\n",
       "      <th>CGabs</th>\n",
       "      <th>CHabs</th>\n",
       "      <th>FPabs</th>\n",
       "      <th>ERabs</th>\n",
       "      <th>BHabs</th>\n",
       "      <th>RIabs</th>\n",
       "      <th>CSabs</th>\n",
       "      <th>EHabs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>4.375278</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>6.375556</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REU03_1</td>\n",
       "      <td>8.375833</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Treatments      Time  Inulin  Starch  Pectin  ArGal  Gum  AmAc   pH  \\\n",
       "0    REU03_1  0.000000     0.5     0.0     0.0    0.0  0.5   0.0  1.0   \n",
       "1    REU03_1  2.375000     0.5     0.0     0.0    0.0  0.5   0.0  1.0   \n",
       "2    REU03_1  4.375278     0.5     0.0     0.0    0.0  0.5   0.0  1.0   \n",
       "3    REU03_1  6.375556     0.5     0.0     0.0    0.0  0.5   0.0  1.0   \n",
       "4    REU03_1  8.375833     0.5     0.0     0.0    0.0  0.5   0.0  1.0   \n",
       "\n",
       "         OD  ...     PJabs     ACabs     CGabs     CHabs     FPabs     ERabs  \\\n",
       "0  0.010000  ...  0.000667  0.000667  0.000667  0.000667  0.000667  0.000667   \n",
       "1  0.042733  ...  0.000667  0.000667  0.000667  0.000667  0.000667  0.000667   \n",
       "2  0.047980  ...  0.000667  0.000667  0.000667  0.000667  0.000667  0.000667   \n",
       "3  0.055872  ...  0.000667  0.000667  0.000667  0.000667  0.000667  0.000667   \n",
       "4  0.070998  ...  0.000667  0.000667  0.000667  0.000667  0.000667  0.000667   \n",
       "\n",
       "      BHabs     RIabs     CSabs     EHabs  \n",
       "0  0.000667  0.000667  0.000667  0.000667  \n",
       "1  0.000667  0.000667  0.000667  0.000667  \n",
       "2  0.000667  0.000667  0.000667  0.000667  \n",
       "3  0.000667  0.000667  0.000667  0.000667  \n",
       "4  0.000667  0.000667  0.000667  0.000667  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert initial OD \n",
    "#avg_mono_data[species] = np.ceil(avg_data.iloc[t0_inds, species_inds].values[0]) / len(species)\n",
    "avg_mono_data[species] = avg_data.iloc[t0_inds, species_inds].values[0]\n",
    "avg_mono_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to make predictions on test data\n",
    "\n",
    "def test_model(model, df_test, max_od, species, plot=False):\n",
    "    all_treatments = df_test.Treatments.values\n",
    "    unique_treatments = np.unique(all_treatments)\n",
    "    numspecies = len(species)\n",
    "\n",
    "    # save true and predicted values\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_std  = []\n",
    "    test_treatments = []\n",
    "    test_times = []\n",
    "    all_species_names = []\n",
    "\n",
    "    # pull a random community trajectory\n",
    "    for treatment in unique_treatments:\n",
    "        comm_inds = np.in1d(df_test['Treatments'].values, treatment)\n",
    "        comm_data = df_test.iloc[comm_inds].copy()\n",
    "\n",
    "        # make sure comm_data is sorted in chronological order\n",
    "        comm_data.sort_values(by='Time', ascending=True, inplace=True)\n",
    "        tspan = comm_data.Time.values\n",
    "\n",
    "        # pull just the community data\n",
    "        output_true = comm_data[species].values\n",
    "\n",
    "        # run model using parameters\n",
    "        x_test = np.copy(output_true[0, :])\n",
    "        \n",
    "        # control parameters \n",
    "        ctrl_params = comm_data[inputs].values #[0]\n",
    "\n",
    "        # test full community\n",
    "        output, stdv, COV = model.predict(x_test, tspan, ctrl_params=ctrl_params)\n",
    "        \n",
    "        # un-normalize\n",
    "        output_true *= max_od\n",
    "        output *= max_od\n",
    "        stdv   *= max_od\n",
    "\n",
    "        # save predictions after initial value \n",
    "        for i, (true, pred, std) in enumerate(zip(output_true[1:], output[1:], stdv[1:])):\n",
    "            y_true += list(true)\n",
    "            y_pred += list(pred)\n",
    "            y_std  += list(std)\n",
    "            test_times += [tspan[i+1]]*numspecies\n",
    "            all_species_names += list(species)\n",
    "            test_treatments += [treatment]*numspecies\n",
    "\n",
    "        if plot:\n",
    "            # increase teval\n",
    "            t_eval = np.linspace(0, tspan[-1]+1)\n",
    "            steps = len(t_eval)\n",
    "            output, stdv, COV = model.predict(x_test, t_eval, ctrl_params=ctrl_params)   \n",
    "            \n",
    "            # un-normalize\n",
    "            output *= max_od\n",
    "            stdv   *= max_od\n",
    "\n",
    "            # plot the results\n",
    "            plt.figure(figsize=(9, 6))\n",
    "            ylim = 0\n",
    "            for i in range(numspecies):\n",
    "                out = output[:,i]\n",
    "                out_true = output_true[:, i]\n",
    "                std = stdv[:, i]\n",
    "                if ylim < np.max([np.max(out) + np.max(std)+.1, np.max(out_true)+.1]):\n",
    "                    ylim = np.max([np.max(out) + np.max(std)+.1, np.max(out_true)+.1])\n",
    "                if out[0] > 0:\n",
    "                    plt.scatter(tspan, out_true, color='C{}'.format(i))\n",
    "                    plt.plot(t_eval, out, label=\"Predicted species \" + str(i+1), color='C{}'.format(i))\n",
    "                    plt.fill_between(t_eval, out-std, out+std, color='C{}'.format(i), alpha=0.2)\n",
    "\n",
    "            plt.xlabel(\"time\", fontsize=16)\n",
    "            plt.ylabel(\"Abundance\", fontsize=16)\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.ylim([0, np.min([ylim, 3])])\n",
    "            plt.title(f\"Treatment {treatment} predictions\")\n",
    "            #plt.savefig(\"Kfold/Figures/{}_{}.pdf\".format(dataset.replace(\"_\",\"\"), treatment.replace(\"<\",\"\")))\n",
    "            #plt.close()\n",
    "            plt.show()\n",
    "\n",
    "    return test_treatments, test_times, all_species_names, y_true, y_pred, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# system dimensions\n",
    "ns = len(species)\n",
    "nu = len(inputs)\n",
    "nx = ns + nu\n",
    "\n",
    "# hidden dimension\n",
    "nh = 8\n",
    "\n",
    "# map to hidden dimension\n",
    "stdv = 1./np.sqrt(nx)\n",
    "A = np.random.uniform(0, stdv, [nh, nx])\n",
    "\n",
    "# init bias term\n",
    "a = np.random.uniform(0, stdv, nh)\n",
    "\n",
    "# map back to original dimension\n",
    "stdv = 1./np.sqrt(nh)\n",
    "B = np.random.uniform(-stdv, 0, [ns, nh])\n",
    "\n",
    "# init growth rates\n",
    "b = np.random.uniform(0, stdv, ns)\n",
    "\n",
    "# init carrying capacities \n",
    "t0_inds = avg_data.Time.values == 0.\n",
    "c = 1./np.max(avg_data[species].values, 0)\n",
    "\n",
    "# concatenate parameters \n",
    "params = np.concatenate((A.flatten(), a, B.flatten(), b, c))\n",
    "prior  = np.zeros_like(params)\n",
    "prior[-ns:] = c\n",
    "\n",
    "n_params = len(params)\n",
    "n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NODE model \n",
    "def system(t, s, params, ctrl_params): \n",
    "\n",
    "    # append species to ctrl params\n",
    "    x = jnp.concatenate((s, ctrl_params[0]))\n",
    "    \n",
    "    # map to hidden dimension\n",
    "    A = jnp.reshape(params[:nh*nx], [nh,nx])\n",
    "    a = params[nh*nx:nh*nx+nh]\n",
    "\n",
    "    # map back to original dimension\n",
    "    B = jnp.reshape(params[nh*nx+nh:nh*nx+nh+nh*ns], [ns,nh])\n",
    "    b = params[nh*nx+nh+nh*ns:nh*nx+nh+nh*ns+ns]\n",
    "\n",
    "    # carrying capacity\n",
    "    c = params[nh*nx+nh+nh*ns+ns:nh*nx+nh+nh*ns+ns+ns]\n",
    "    \n",
    "    # compute hidden dimension\n",
    "    h = jnp.tanh(A@x + a)\n",
    "\n",
    "    # rate of change of species \n",
    "    dsdt = s * (B@h + b) * (1. - c*s)\n",
    "\n",
    "    return dsdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define compression functions \n",
    "compressor0 = lambda x: jnp.expand_dims(jnp.sum(x*max_od), 0)     # sum over outputs \n",
    "compressor1 = lambda x: x\n",
    "\n",
    "compressors = [compressor0, compressor1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ODE (time, x, parameters, u(t), control parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          2.375       4.37527778  6.37555556  8.37583333 10.37638889\n",
      " 12.37666667 14.37722222 16.37777778 18.37805556 20.37861111 22.37861111\n",
      " 24.37888889 26.37916667]\n",
      "[ 0.   26.37]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38375/3177820474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 verbose=True)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# fit to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "# pull treatment names \n",
    "all_mono_treatments = avg_mono_data.Treatments.values\n",
    "all_treatments = avg_data.Treatments.values\n",
    "unique_treatments = np.unique(all_treatments)\n",
    "\n",
    "# set up kfold iterator\n",
    "kf = KFold(n_splits = K) \n",
    "\n",
    "# set up list of measured and predicted values\n",
    "kfold_species_names = []\n",
    "kfold_y_true = []\n",
    "kfold_y_pred = []\n",
    "kfold_y_stdv = []\n",
    "\n",
    "# iterate over folds \n",
    "for train_index, test_index in kf.split(unique_treatments):\n",
    "    # train_index, test_index = next(iter(kf.split(unique_treatments)))\n",
    "\n",
    "    # get index of train and test data\n",
    "    train_inds_mono = np.in1d(all_mono_treatments, unique_treatments[train_index])\n",
    "    train_inds = np.in1d(all_treatments, unique_treatments[train_index])\n",
    "    test_inds  = np.in1d(all_treatments, unique_treatments[test_index])\n",
    "\n",
    "    # pull out train and test data \n",
    "    df_train_mono = avg_mono_data.iloc[train_inds_mono].copy()\n",
    "    df_train = avg_data.iloc[train_inds].copy()\n",
    "    df_test  = avg_data.iloc[test_inds].copy()\n",
    "\n",
    "    # instantiate gLV fit \n",
    "    model = ODE(system = system, \n",
    "                dataframes=[df_train_mono, df_train],\n",
    "                compressors = compressors,\n",
    "                params = params, \n",
    "                prior = prior,\n",
    "                sys_vars = species,\n",
    "                measured_vars = [['OD'], species],\n",
    "                controls = inputs,\n",
    "                verbose=True)\n",
    "    \n",
    "    # fit to data \n",
    "    t0 = time.time()\n",
    "    model.fit(evidence_tol=1e-3, beta_tol=1e-4)\n",
    "    print(\"Elapsed time {:.2f}s\".format(time.time()-t0))\n",
    "\n",
    "    # predict held-out data\n",
    "    test_treatments, test_times, all_species_names, y_true, y_pred, y_std = test_model(model, df_test, max_od, species, plot=False)\n",
    "    kfold_species_names += all_species_names\n",
    "    kfold_y_true += y_true\n",
    "    kfold_y_pred += y_pred\n",
    "    kfold_y_stdv += y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_treatments, test_times, all_species_names, y_true, y_pred, y_std = test_model(model, avg_data, max_od, species, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vals = []\n",
    "plt.figure(figsize=(9,8))\n",
    "for s in species:\n",
    "    y_inds = np.in1d(all_species_names, s)\n",
    "    y_s_true = np.array(y_true)[y_inds]\n",
    "    y_s_pred = np.array(y_pred)[y_inds]\n",
    "    \n",
    "    r = linregress(y_s_true, y_s_pred).rvalue\n",
    "    r_vals.append(r)\n",
    "    plt.scatter(y_s_true, y_s_pred, label=s.replace(\"abs\",\"\")+\" R={:.2f}\".format(r))\n",
    "plt.legend()\n",
    "plt.xlabel(\"Measured\", fontsize=18)\n",
    "plt.ylabel(\"Predicted\", fontsize=18)\n",
    "\n",
    "plt.savefig(\"Results/node_fit_mf.pdf\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,8))\n",
    "r_vals = []\n",
    "for s in species:\n",
    "    y_inds = np.in1d(kfold_species_names, s)\n",
    "    y_s_true = np.array(kfold_y_true)[y_inds]\n",
    "    y_s_pred = np.array(kfold_y_pred)[y_inds]\n",
    "    \n",
    "    r = linregress(y_s_true, y_s_pred).rvalue\n",
    "    r_vals.append(r)\n",
    "    plt.scatter(y_s_true, y_s_pred, label=s.replace(\"abs\",\"\")+\" R={:.2f}\".format(r))\n",
    "plt.legend()\n",
    "#plt.ylim([0,.5])\n",
    "plt.show()\n",
    "print(np.median(r_vals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
