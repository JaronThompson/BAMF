{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from bamf.torchCR import *\n",
    "\n",
    "import time\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# set plot parameters\n",
    "params = {'legend.fontsize': 18,\n",
    "          'figure.figsize': (8, 7),\n",
    "          'axes.labelsize': 24,\n",
    "          'axes.titlesize':24,\n",
    "          'axes.linewidth':3,\n",
    "          'xtick.labelsize':20,\n",
    "          'ytick.labelsize':20}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all pytorch needs to do is provide the gradient of a function\n",
    "from functorch import grad, jacfwd, jacrev\n",
    "\n",
    "def torch_grad(f, argnums):\n",
    "    # \n",
    "    return jacrev(f, argnums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x, A: np.matmul(A, x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.random.randn(3), dtype=torch.float32)\n",
    "A = torch.tensor(np.random.randn(3,3), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8678, -0.9941,  1.2923])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_grad = jacrev(f, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 µs ± 24.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch_grad(x, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "jax_grad = jax.jacrev(lambda x, A: jnp.matmul(A, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49 ms ± 58.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jax_grad(x.numpy(), A.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_grad = jacrev(lambda x, A: A@x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(3)\n",
    "A = np.random.randn(3,3)\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "A = torch.tensor(A, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 µs ± 45.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch_grad(x, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatments</th>\n",
       "      <th>Time</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exp_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086631</td>\n",
       "      <td>0.025046</td>\n",
       "      <td>0.048303</td>\n",
       "      <td>0.098556</td>\n",
       "      <td>0.051949</td>\n",
       "      <td>0.061289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exp_1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.090712</td>\n",
       "      <td>0.215443</td>\n",
       "      <td>0.190611</td>\n",
       "      <td>0.174476</td>\n",
       "      <td>0.032546</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exp_1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.023573</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.282975</td>\n",
       "      <td>0.173349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exp_10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>0.034346</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>0.066662</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>0.013089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exp_10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>0.277299</td>\n",
       "      <td>0.194568</td>\n",
       "      <td>0.172302</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.018922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>exp_8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.105865</td>\n",
       "      <td>0.058858</td>\n",
       "      <td>0.132456</td>\n",
       "      <td>0.164099</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.017758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>exp_8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.083224</td>\n",
       "      <td>0.293845</td>\n",
       "      <td>0.269835</td>\n",
       "      <td>0.161158</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.004992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>exp_9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035591</td>\n",
       "      <td>0.076255</td>\n",
       "      <td>0.059318</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.039888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>exp_9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.054867</td>\n",
       "      <td>0.315027</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.146970</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>0.007899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>exp_9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>0.370071</td>\n",
       "      <td>0.285128</td>\n",
       "      <td>0.133293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Treatments  Time        s1        s2        s3        s4        s5  \\\n",
       "0        exp_1   0.0  0.086631  0.025046  0.048303  0.098556  0.051949   \n",
       "1        exp_1   8.0  0.090712  0.215443  0.190611  0.174476  0.032546   \n",
       "2        exp_1  16.0  0.023573  0.353033  0.282975  0.173349  0.000000   \n",
       "3       exp_10   0.0  0.024086  0.034346  0.051313  0.066662  0.010591   \n",
       "4       exp_10   8.0  0.059290  0.277299  0.194568  0.172302  0.012084   \n",
       "..         ...   ...       ...       ...       ...       ...       ...   \n",
       "187      exp_8   8.0  0.105865  0.058858  0.132456  0.164099  0.075496   \n",
       "188      exp_8  16.0  0.083224  0.293845  0.269835  0.161158  0.025799   \n",
       "189      exp_9   0.0  0.035591  0.076255  0.059318  0.069170  0.015113   \n",
       "190      exp_9   8.0  0.054867  0.315027  0.211837  0.146970  0.027926   \n",
       "191      exp_9  16.0  0.016750  0.370071  0.285128  0.133293  0.000000   \n",
       "\n",
       "           s6  \n",
       "0    0.061289  \n",
       "1    0.002532  \n",
       "2    0.000000  \n",
       "3    0.013089  \n",
       "4    0.018922  \n",
       "..        ...  \n",
       "187  0.017758  \n",
       "188  0.004992  \n",
       "189  0.039888  \n",
       "190  0.007899  \n",
       "191  0.001472  \n",
       "\n",
       "[192 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used later for model validation\n",
    "# gLV_data = pd.read_csv(\"gLV_data/DSM_processed_mono.csv\")\n",
    "gLV_data = pd.read_csv(\"gLV_data/gLV_data_for_CR.csv\")\n",
    "gLV_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s1', 's2', 's3', 's4', 's5', 's6'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get species names\n",
    "species = gLV_data.columns.values[2:]\n",
    "species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimensions \n",
    "n_s = len(species)\n",
    "n_r = 3\n",
    "# input to NN includes species, resources (and maybe also time) \n",
    "n_x = n_s + n_r\n",
    "\n",
    "# CR parameters \n",
    "d = -3.*np.ones(n_s)\n",
    "C = np.random.uniform(-1., 0., [n_r, n_s])\n",
    "P = np.random.uniform(-5., -1., [n_r, n_s])\n",
    "K = np.ones(n_r)\n",
    "\n",
    "# dimension of hidden layer\n",
    "n_h = 4\n",
    "\n",
    "# map to hidden dimension\n",
    "p_std = 1./np.sqrt(n_x)\n",
    "W1 = p_std*np.random.randn(n_h, n_x)\n",
    "b1 = np.random.randn(n_h)\n",
    "\n",
    "# parameters to compute efficiency matrix\n",
    "p_std = 1./np.sqrt(n_h)\n",
    "W2 = p_std*np.random.randn(n_r+2*n_s, n_h) \n",
    "b2 = np.random.randn(n_r+2*n_s)\n",
    "\n",
    "# concatenate parameter initial guess\n",
    "params = np.concatenate((d, W1.flatten(), b1, C.flatten(), W2.flatten(), b2.flatten(), P.flatten(), K))\n",
    "\n",
    "# set prior so that C is sparse \n",
    "W1prior = np.zeros_like(W1)\n",
    "b1prior = np.zeros_like(b1)\n",
    "Cprior = -5.*np.ones([n_r, n_s]) \n",
    "Pprior = -5.*np.ones([n_r, n_s])\n",
    "W2prior = np.zeros_like(W2)\n",
    "b2prior = np.zeros_like(b2)\n",
    "\n",
    "# concatenate prior \n",
    "prior = np.concatenate((d, W1prior.flatten(), b1prior, Cprior.flatten(), W2prior.flatten(), b2prior.flatten(), Pprior.flatten(), K))\n",
    "\n",
    "n_params = len(params)\n",
    "n_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using consumer resource model  \n",
    "def system(t, x, params): \n",
    "    \n",
    "    # species \n",
    "    s = x[:n_s]\n",
    "    \n",
    "    # resources\n",
    "    r = torch.exp(x[n_s:])\n",
    "    \n",
    "    # compute state \n",
    "    state = torch.concatenate((s, r))\n",
    "    \n",
    "    # death rate\n",
    "    d = torch.exp(params[:n_s])\n",
    "    \n",
    "    # map to hidden layer\n",
    "    W1 = torch.reshape(params[n_s:n_s+n_x*n_h], [n_h, n_x])\n",
    "    b1 = params[n_s+n_x*n_h:n_s+n_x*n_h+n_h]\n",
    "    h1 = torch.tanh(W1@state + b1)\n",
    "    \n",
    "    # maximum consumption rate parameters\n",
    "    Cmax = torch.exp(torch.reshape(params[n_s+n_x*n_h+n_h:n_s+n_x*n_h+n_h+n_r*n_s], [n_r, n_s]))\n",
    "    \n",
    "    # attractiveness of resource i to species j / consumption efficiency\n",
    "    W2 = torch.reshape(params[n_s+n_x*n_h+n_h+n_r*n_s:n_s+n_x*n_h+n_h+n_r*n_s+(n_r+2*n_s)*n_h], [n_r+2*n_s, n_h])\n",
    "    b2 = torch.reshape(params[n_s+n_x*n_h+n_h+n_r*n_s+(n_r+2*n_s)*n_h:n_s+n_x*n_h+n_h+n_r*n_s+(n_r+2*n_s)*n_h+n_r+2*n_s], [n_r+2*n_s])\n",
    "    h2 = torch.sigmoid(W2@h1 + b2)\n",
    "    \n",
    "    # divide hidden layer into resource availability, species growth efficiency, resource production efficiency\n",
    "    f = h2[:n_r]\n",
    "    g = h2[n_r:n_r+n_s]\n",
    "    h = h2[n_r+n_s:]\n",
    "    \n",
    "    # update Consumption matrix according to resource attractiveness \n",
    "    C = torch.einsum(\"i,ij->ij\", f, Cmax)\n",
    "    \n",
    "    # max production rate\n",
    "    Pmax = torch.exp(torch.reshape(params[n_s+n_x*n_h+n_h+n_r*n_s+(n_r+2*n_s)*n_h+n_r+2*n_s:n_s+n_x*n_h+n_h+n_r*n_s+(n_r+2*n_s)*n_h+n_r+2*n_s+n_r*n_s], [n_r, n_s]))\n",
    "    K = torch.exp(params[n_s+n_x*n_h+n_h+n_r*n_s+(n_r+2*n_s)*n_h+n_r+2*n_s+n_r*n_s:])\n",
    "    \n",
    "    # scaled production rate\n",
    "    P = torch.einsum(\"ij,j->ij\", Pmax, h)\n",
    "    \n",
    "    # rate of change of species \n",
    "    dsdt = s*(g*(C.T@r) - d)\n",
    "\n",
    "    # rate of change of log of resources \n",
    "    dlrdt = (1. - r/K) * ((P-C)@s) \n",
    "\n",
    "    return torch.concatenate((dsdt, dlrdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x9 and 1x9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8975/579100631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8975/480376057.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(t, x, params)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# maximum consumption rate parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x9 and 1x9)"
     ]
    }
   ],
   "source": [
    "system(1., torch.tensor([np.ones(9)]), torch.tensor(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define observation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define observation matrices \n",
    "O = np.zeros([n_s, n_s+n_r])\n",
    "O[:n_s,:n_s] = np.eye(n_s)\n",
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model to mono culture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([n_s, n_r, n_h], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.80186387 -1.72707942 -1.31334486]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n\naten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a):\nExpected a value of type 'List[int]' for argument 'shape' but instead found type 'List[Tensor]'.\nEmpty lists default to List[Tensor]. Add a variable annotation to the assignment to create an empty list of another type (torch.jit.annotate(List[T, []]) where T is the type of elements in the list for Python 2)\n:\n  File \"/tmp/ipykernel_8975/1259436785.py\", line 23\n    \n    # map to hidden layer\n    W1 = torch.reshape(params[n_s:n_s+n_x*n_h], [n_h, n_x])\n         ~~~~~~~~~~~~~ <--- HERE\n    b1 = params[n_s+n_x*n_h:n_s+n_x*n_h+n_h]\n    h1 = torch.tanh(W1@state + b1)\n'system' is being compiled since it was called from 'dX_dt'\n  File \"/home/jaron/Documents/BAMF/bamf/torchCR.py\", line 187\n        def dX_dt(t, x, params):\n            # concatentate x and z\n            return system(t, x, params)\n                   ~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8975/2541843479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model = ODE(system = system, \n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgLV_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/BAMF/bamf/torchCR.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, system, dataframe, C, CRparams, shapes, r0, species, alpha_0, f_ind, batch_size, prior, verbose)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;31m# concatentate x and z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdX_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# adjoint sensitivity derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_rcb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0m_rcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateResolutionCallbackFromClosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         fn = torch._C._jit_script_compile(\n\u001b[0m\u001b[1;32m   1344\u001b[0m             \u001b[0mqualified_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_default_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mtry_compile_fn\u001b[0;34m(fn, loc)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;31m# object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0mrcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateResolutionCallbackFromClosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrap_cpp_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_rcb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0m_rcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateResolutionCallbackFromClosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         fn = torch._C._jit_script_compile(\n\u001b[0m\u001b[1;32m   1344\u001b[0m             \u001b[0mqualified_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_default_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n\naten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a):\nExpected a value of type 'List[int]' for argument 'shape' but instead found type 'List[Tensor]'.\nEmpty lists default to List[Tensor]. Add a variable annotation to the assignment to create an empty list of another type (torch.jit.annotate(List[T, []]) where T is the type of elements in the list for Python 2)\n:\n  File \"/tmp/ipykernel_8975/1259436785.py\", line 23\n    \n    # map to hidden layer\n    W1 = torch.reshape(params[n_s:n_s+n_x*n_h], [n_h, n_x])\n         ~~~~~~~~~~~~~ <--- HERE\n    b1 = params[n_s+n_x*n_h:n_s+n_x*n_h+n_h]\n    h1 = torch.tanh(W1@state + b1)\n'system' is being compiled since it was called from 'dX_dt'\n  File \"/home/jaron/Documents/BAMF/bamf/torchCR.py\", line 187\n        def dX_dt(t, x, params):\n            # concatentate x and z\n            return system(t, x, params)\n                   ~~~~~~~~~~~~~~~~~~~ <--- HERE\n"
     ]
    }
   ],
   "source": [
    "r0 = np.random.uniform(-3, 0, n_r)\n",
    "print(r0)\n",
    "\n",
    "model = ODE(system = system, \n",
    "            dataframe=gLV_data,\n",
    "            C=O,\n",
    "            CRparams = params, \n",
    "            shapes = [n_s, n_r, n_h],\n",
    "            r0 = r0,\n",
    "            prior = prior,\n",
    "            species = species,\n",
    "            alpha_0=1e-5,\n",
    "            verbose=True)\n",
    "\n",
    "# fit to data \n",
    "t0 = time.time()\n",
    "model.fit(evidence_tol=1e-3, nlp_tol=1e-3, patience=1, max_fails=1)\n",
    "print(\"Elapsed time {:.2f}s\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(self):\n",
    "    # loop over each sample in dataset\n",
    "    for n_t, (t_eval, Y_batch) in self.dataset.items():\n",
    "\n",
    "        # split samples into batches\n",
    "        n_samples = Y_batch.shape[0]\n",
    "        for batch_inds in np.array_split(np.arange(n_samples), n_samples//self.batch_size):\n",
    "            \n",
    "            # run model using current parameters, output = [n_time, self.n_sys_vars]\n",
    "            outputs = np.nan_to_num(self.batchODEZ(t_eval, Y_batch[batch_inds], self.params[:self.n_r], self.params[self.n_r:]))\n",
    "            \n",
    "            \n",
    "def forward(self):\n",
    "    # loop over each sample in dataset\n",
    "    for n_t, (t_eval, Y_batch) in self.dataset.items():\n",
    "\n",
    "        # split samples into batches\n",
    "        for Y_measured in Y_batch:\n",
    "\n",
    "            # run model using current parameters, output = [n_time, self.n_sys_vars]\n",
    "            output = np.nan_to_num(self.runODEZ(t_eval, Y_measured, self.params[:self.n_r], self.params[self.n_r:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_size = 4\n",
    "model.batch_size\n",
    "\n",
    "model.batchODEZ = jit(vmap(model.runODEZ, (None, 0, None, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit batch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit forward(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
